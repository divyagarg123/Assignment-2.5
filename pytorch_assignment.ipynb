{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9wJf07hOHJyL"
      },
      "outputs": [],
      "source": [
        "import torch    #Import torch module \n",
        "import torchvision #Import torchvision\n",
        "import torchvision.transforms as transforms #Import transforms for data transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bFHaymKyHeFx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset # Import Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "g2fKJMpDKVbA"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):                  # Create a custom Dataset Class\n",
        "\n",
        "  def __init__(self, device='cuda'):\n",
        "    train_set = torchvision.datasets.FashionMNIST(       # Download fashionMNIST Dataset\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    )\n",
        "    self.data=[]\n",
        "    self.data2=[]\n",
        "    self.label_0=[]\n",
        "    self.label_1=[]\n",
        "    for i in train_set:\n",
        "      # Create sample by combining each image with numbers 0-9 so for each image we will have 10 samples.\n",
        "      comb_0 = [i[0] for j in range(10)]    # Image\n",
        "      comb_1 =  [torch.tensor(j, dtype=torch.float32) for j in range(10)] # Image label\n",
        "      # Create label with two things(image class number, image class number +(0-9)) \n",
        "      label_00 = [i[1] for j in range(10)]    \n",
        "      label_11 = [torch.tensor(i[1]+j) for j in range(10)]         \n",
        "      for train_i,train_j in  zip(comb_0,comb_1):\n",
        "        self.data.append(train_i)\n",
        "        self.data2.append(train_j)\n",
        "      for l,l1 in zip(label_00, label_11):\n",
        "        self.label_0.append(l)\n",
        "        self.label_1.append(l1)\n",
        "      \n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.data[index],self.data2[index], self.label_0[index], self.label_1[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rxTBUBAJgzPi"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2  = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=70, out_features=10)\n",
        "  \n",
        "  def forward(self, t, t1):\n",
        "    x = t          # Take first input -> Image\n",
        "    x1 = t1         # Take second input -> random number\n",
        "    x = self.conv1(x)    # Apply convolutions, relu and max pool on image input\n",
        "    x= F.relu(x)\n",
        "    x= F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x= F.relu(x)\n",
        "    x= F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "    x = x.reshape(-1,12*4*4)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.fc2(x)         # dimension is 60 for image data(first input)\n",
        "    #print(x1)\n",
        "    x2 = F.one_hot(x1.long(),10)   # One hot encode second input so we get vector of dimension 10\n",
        "    x = torch.cat((x, x2), dim=1)  # combine first output and seconf output to form a single vector of length 70\n",
        "\n",
        "    x = self.out(x)            # apply a linear layer to convert 70 features to 10 features\n",
        "    x = F.softmax(x, dim=0)    # apply softmax\n",
        "    out = torch.argmax(x,dim=1) # retrieve the image prediction no.\n",
        "    return x, out+x1            # return softmax output, image prediction no + random no \n",
        "network = Network()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rIbfKUgY_DLG"
      },
      "outputs": [],
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HXFrgoVMGZ4H"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')\n",
        "print(\"Using {}.\".format(device_name))"
      ],
      "metadata": {
        "id": "0wM5RcbakqBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77297aef-32d8-4f82-a79a-db805124c6bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kUH4uLQ8iAd",
        "outputId": "cf51b630-8a8f-41c6-af1a-705c1e1c8c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_loss:  2.304561171849569 total_correct:  62922\n",
            "total_loss:  2.3041157370758056 total_correct:  62722\n",
            "total_loss:  2.298062359873454 total_correct:  67202\n",
            "total_loss:  2.2931556158447264 total_correct:  69152\n",
            "total_loss:  2.2928664020284018 total_correct:  69763\n",
            "total_loss:  2.302566183827718 total_correct:  62406\n",
            "total_loss:  2.3113403741200766 total_correct:  59008\n",
            "total_loss:  2.3077816186269122 total_correct:  59860\n",
            "total_loss:  2.3069199922943113 total_correct:  60141\n",
            "total_loss:  2.308131017735799 total_correct:  59625\n",
            "total_loss:  2.309306469599406 total_correct:  59937\n",
            "total_loss:  2.3080953948465983 total_correct:  60805\n",
            "total_loss:  2.3157895592753093 total_correct:  60643\n",
            "total_loss:  2.3204255466715495 total_correct:  58774\n",
            "total_loss:  2.317178121210734 total_correct:  56019\n",
            "total_loss:  2.307277942682902 total_correct:  60593\n",
            "total_loss:  2.3074359098815918 total_correct:  63477\n",
            "total_loss:  2.3088055672709147 total_correct:  61244\n",
            "total_loss:  2.3096833536020913 total_correct:  63407\n",
            "total_loss:  2.313846346537272 total_correct:  60793\n"
          ]
        }
      ],
      "source": [
        "network = Network()\n",
        "network.to(device_name)\n",
        "my_data = MyDataset()\n",
        "train_loader = torch.utils.data.DataLoader(    # Initialize DataLoader to have batch size 64 \n",
        "    my_data, \n",
        "    batch_size = 64, \n",
        "    shuffle=True\n",
        ")\n",
        "optimizer = optim.Adam(network.parameters(), lr = 0.01)   # Initialize optimizer with learning rate 0.01\n",
        "for epoch in range(50):\n",
        "  total_loss=0\n",
        "  total_correct=0\n",
        "  total = 0\n",
        "  for batch in train_loader:\n",
        "    sample,sample2, label0, label1=batch\n",
        "    #print(label0, label1, sample2)\n",
        "    sample=sample.to(device_name)\n",
        "    sample2=sample2.to(device_name)\n",
        "    label0=label0.to(device_name)\n",
        "    label1=label1.to(device_name)\n",
        "    total = total + 1\n",
        "    pred=network(sample, sample2)\n",
        "    loss = F.cross_entropy(pred[0], label0)  # Use loss to compare only image prediction . On basis of that we will change the gradient\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "    total_correct += get_num_correct(pred[0], label0)\n",
        "  print(\"total_loss: \", total_loss/total, \"total_correct: \",total_correct)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCNt4PEq90DE"
      },
      "outputs": [],
      "source": [
        "()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nxJ_S6g2iz98"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}